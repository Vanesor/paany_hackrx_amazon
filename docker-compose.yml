version: "3.8"

services:
  rag-system:
    build: .
    container_name: rag-system
    ports:
      - "8000:8000"
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - CACHE_DIR=/app/cache
      - MODEL_CACHE_DIR=/app/models
      - NLTK_DATA=/app/nltk_data
      - PYTHONPATH=/app
      - TRANSFORMERS_CACHE=/app/models
      - SENTENCE_TRANSFORMERS_HOME=/app/models
      - HF_HOME=/app/models
      # Accuracy-focused configuration
      - RAG_MODE=ACCURACY
      - BGE_MODEL=BAAI/bge-base-en-v1.5
      - RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
    volumes:
      - ./cache:/app/cache
      - ./downloads:/app/downloads
      - ./models:/app/models
      - ./auto_downloads:/app/auto_downloads
    networks:
      - rag-network
    restart: unless-stopped
    # Resource limits optimized for 2GB RAM accuracy system
    deploy:
      resources:
        limits:
          memory: 1.8G  # Increased for BGE-base model
          cpus: '1.9'   # More CPU for accuracy processing
        reservations:
          memory: 1.4G  # Higher baseline for BGE-base
          cpus: '1.2'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 15s    # Longer timeout for accuracy models
      retries: 3
      start_period: 120s  # More time for BGE-base loading

volumes:
  # Remove redis-data volume as Redis is no longer used
  model-cache:
    driver: local
  app-cache:
    driver: local

networks:
  rag-network:
    driver: bridge
